{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019114005_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Kv2dXytw54"
      },
      "source": [
        "import string\n",
        "import torch\n",
        "import re\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQCulMwt3MS"
      },
      "source": [
        "def _basic_english_normalize(line):\n",
        "\n",
        "    temp = line.lower()\n",
        "    regex = \"[^\\w\\s]\"\n",
        "    temp = re.sub(r\"[^\\w\\s]\", '', temp)\n",
        "    ans = temp.split()\n",
        "    return ans"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDVaMAe0t8mF"
      },
      "source": [
        "def one_hot_encoding(dataset, dimensions):\n",
        "\n",
        "    one_hot_encoded = list()\n",
        "    counter = 0\n",
        "    for data in dataset:\n",
        "        counter += 1\n",
        "        embedding = []\n",
        "        small_counter = 0\n",
        "        for int in data:\n",
        "            small_counter += 1\n",
        "            word_embedding = np.zeros(dimensions)\n",
        "            word_embedding[int] = 1\n",
        "            embedding.append(word_embedding)\n",
        "    ans = np.array(embedding)\n",
        "    one_hot_encoded.append(ans)\n",
        "    sol = np.array(one_hot_encoded)\n",
        "    return sol"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJU7iiukuDDv"
      },
      "source": [
        "def get_tokens(sentences):\n",
        "    \n",
        "    counter = 0\n",
        "    tokens = list()\n",
        "    for line in sentences:\n",
        "        counter += 1\n",
        "        normalized_line = _basic_english_normalize(line)\n",
        "        token_counter = 0\n",
        "        for word in normalized_line:\n",
        "            token_counter += 1\n",
        "            tokens.append(word)\n",
        "\n",
        "    return tokens"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjyuvLHSuF78"
      },
      "source": [
        "def create_mini_batches(arr, batch_size, seq_length):\n",
        "    \n",
        "    num_tokens_in_each_batch = batch_size * seq_length\n",
        "    arr_len = len(arr)\n",
        "    K = arr_len // num_tokens_in_each_batch\n",
        "    split = num_tokens_in_each_batch * K\n",
        "    arr = arr[:split].reshape((batch_size, -1))\n",
        "\n",
        "    for i in range(0, arr.shape[1], seq_length):\n",
        "        temp_size = i + seq_length\n",
        "        x = arr[:, i:temp_size]\n",
        "        check = 0\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            check = 1\n",
        "            y[:, :-1] = x[:, 1:]\n",
        "            y[:, -1] = arr[:, temp_size]\n",
        "        except IndexError:\n",
        "            check = 2\n",
        "            y[:, :-1] = x[:, 1:]\n",
        "            y[:, -1] = arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "EFP2r6ECuOnU",
        "outputId": "ab4f4530-c2f8-4d9f-e126-818266ba3d5c"
      },
      "source": [
        "data = 'brown.txt'\n",
        "with open(data, 'r', encoding=\"utf8\") as f:\n",
        "    sentences = f.readlines()\n",
        "\n",
        "a = 28946\n",
        "b = 48947\n",
        "c = 18946\n",
        "test_set = sentences[a:b]\n",
        "train_set = sentences[:c]\n",
        "validation_set = sentences[c:a]\n",
        "\n",
        "tokens = get_tokens(train_set)\n",
        "vocab = sorted(list(set(tokens)))\n",
        "print(len(sentences), len(train_set), len(validation_set), len(test_set))\n",
        "vocab_size = len(vocab)\n",
        "int2word = dict(enumerate(vocab))\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "word2int = {word:integer for integer, word in int2word.items()}\n",
        "vocab_size = len(word2int)\n",
        "encoded_sentence = np.array([word2int[word] for word in tokens])\n",
        "print(encoded_sentence.shape)\n",
        "print('Unique Tokens: %d' % vocab_size)\n",
        "if(not torch.cuda.is_available()):\n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
        "else:\n",
        "    print('Training on GPU!')\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d8b7281330ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'brown.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28946\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'brown.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zH04kELuYO7"
      },
      "source": [
        "class LanguageRNN(nn.Module):\n",
        "    checker = 0\n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, learn_rate=0.001):\n",
        "        a_count = 0\n",
        "        super().__init__()\n",
        "        self.vocab = tokens\n",
        "        self.int2word = dict(enumerate(self.vocab))\n",
        "        self.n_hidden = n_hidden\n",
        "        vocab_size = len(self.vocab)\n",
        "        self.n_layers = n_layers\n",
        "        self.drop_prob = drop_prob\n",
        "        self.learn_rate = learn_rate\n",
        "        self.word2int = {word: int for int, word in self.int2word.items()}\n",
        "        a_count = 0\n",
        "        self.lstm = nn.LSTM(vocab_size, n_hidden, n_layers, dropout = drop_prob, batch_first = True)\n",
        "        prob = drop_prob\n",
        "        self.dropout = nn.Dropout(prob)\n",
        "        checker = 1\n",
        "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        checker = 2\n",
        "        last_output, last_hidden_state = self.lstm(x, hidden)\n",
        "        final_output = self.dropout(last_output)\n",
        "        temp = []\n",
        "        final_output = final_output.contiguous().view(-1, self.n_hidden)\n",
        "        temp.append(final_output)\n",
        "        final_output = self.fc(final_output)\n",
        "\n",
        "        return final_output, last_hidden_state\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        weight = next(self.parameters()).data\n",
        "        if (not train_on_gpu):\n",
        "            temp_1 = weight.new(self.n_layers, batch_size, self.n_hidden).zero_()\n",
        "            temp_2 = weight.new(self.n_layers, batch_size, self.n_hidden).zero_()\n",
        "            hidden = (temp_1, temp_2)\n",
        "        else:\n",
        "            temp_1 = weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda()\n",
        "            temp_2 = weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda()\n",
        "            hidden = (temp_1, temp_2)\n",
        "        checker = 3\n",
        "        return hidden"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "oeY4EBtJufyU",
        "outputId": "89346ab6-6715-40d8-cc91-66b8077711f1"
      },
      "source": [
        "a_len = len(test_set)\n",
        "\n",
        "EPOCH_SIZE = 10\n",
        "BATCH_SIZE = 10\n",
        "SEQ_LENGTH = 20\n",
        "LEARN_RATE = 0.001\n",
        "GRADIENT_CLIP = 5\n",
        "VAL_FRAC = 0.1\n",
        "PRINT_FREQ = 5\n",
        "n_hidden=512\n",
        "n_layers=1\n",
        "batch_size = 90\n",
        "seq_length = 20\n",
        "n_epochs = 2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-84fe803e6fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSEQ_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "T55q7Jfyukxl",
        "outputId": "0424ddab-9977-44b3-d73e-158d30e354eb"
      },
      "source": [
        "def train(RNN, data, epochs = EPOCH_SIZE, batch_size = BATCH_SIZE, seq_length = SEQ_LENGTH, learn_rate = LEARN_RATE, gradient_clip = GRADIENT_CLIP, val_frac = VAL_FRAC, print_freq = PRINT_FREQ):\n",
        "    checker = 0\n",
        "    RNN.train()\n",
        "    temp = learn_rate\n",
        "    optimizer = torch.optim.Adam(RNN.parameters(), lr=temp)\n",
        "    gpu_check = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        gpu_check = 1\n",
        "        RNN.cuda()\n",
        "    a = len(data)\n",
        "    b = 1 - val_frac\n",
        "    val_idx = int(a * b)\n",
        "    data = data[:val_idx], \n",
        "    val_data = data[val_idx:]\n",
        "    dimension = len(RNN.vocab)\n",
        "    counter = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        h = RNN.init_hidden(batch_size)\n",
        "        is_gpu = 0\n",
        "        for x, y in create_mini_batches(data, batch_size, seq_length):\n",
        "            x = one_hot_encoding(x, dimension)\n",
        "            counter = counter + 1\n",
        "            inputs = torch.from_numpy(x).float()\n",
        "            targets = torch.from_numpy(y).float()\n",
        "            if (train_on_gpu):\n",
        "                inputs = inputs.cuda()\n",
        "                is_gpu = 1\n",
        "                targets = targets.cuda()\n",
        "\n",
        "            bc = counter % print_freq \n",
        "            h = tuple([each.data for each in h])\n",
        "            RNN.zero_grad()\n",
        "            temp = batch_size * seq_length\n",
        "            output, h = RNN(inputs, h)\n",
        "            loss = criterion(output, targets.view(temp).long())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(RNN.parameters(), gradient_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            if bc == 0:\n",
        "                val_losses = []\n",
        "                val_h = RNN.init_hidden(batch_size)\n",
        "                RNN.eval()\n",
        "                for x, y in create_mini_batches(val_data, batch_size, seq_length):\n",
        "                    x = one_hot_encoding(x, dimension)\n",
        "                    i = []\n",
        "                    x = torch.from_numpy(x).float()\n",
        "                    y = torch.from_numpy(y).float()\n",
        "                    inputs = x\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    targets = y\n",
        "\n",
        "                    if (train_on_gpu):\n",
        "                        inputs = inputs.cuda() \n",
        "                        targets = targets.cuda()\n",
        "                    mult = batch_size * seq_length\n",
        "                    output, val_h = RNN(inputs, val_h)\n",
        "                    ch = targets.view(mult).long()\n",
        "                    val_loss = criterion(output, ch)\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                RNN.train()\n",
        "                # print(\"Epoch: {}/{}...\".format(e+1, epochs), \"Step: {}...\".format(counter), \"Loss: {:.4f}...\".format(loss.item()), \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-05e8e5f56000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARN_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRADIENT_CLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_frac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAL_FRAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRINT_FREQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mchecker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EPOCH_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "F-pTV4x0utXH",
        "outputId": "c80953f8-8664-41c0-fb45-b3f0e06eb93a"
      },
      "source": [
        "train(RNN, encoded_sentence, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, learn_rate=LEARN_RATE, print_freq=PRINT_FREQ//5)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3279917ffc5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARN_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRINT_FREQ\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "gQGDufrmut9M",
        "outputId": "8fbdfda4-9f21-45d5-e0c0-28cbc52fe54d"
      },
      "source": [
        "model_name = 'rnn_1_layer_epoch_18000_data.net'\n",
        "checkpoint = {}\n",
        "checkpoint['n_hidden'] = RNN.n_hidden\n",
        "checkpoint['n_layers'] = RNN.n_layers\n",
        "checkpoint['state_dict'] = RNN.state_dict()\n",
        "checkpoint['tokens'] = RNN.vocab\n",
        "# checkpoint = {'n_hidden': RNN.n_hidden, 'n_layers': RNN.n_layers, 'state_dict': RNN.state_dict(), 'tokens': RNN.vocab}\n",
        "\n",
        "with open(model_name, 'wb') as f:\n",
        "    torch.save(checkpoint, f)\n",
        "\n",
        "N = None"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e123ff044157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rnn_1_layer_epoch_18000_data.net'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_hidden'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_layers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "ezuD7Ugvu7h_",
        "outputId": "51793de6-81cb-4099-aaba-89a20d0daae4"
      },
      "source": [
        "def predict(RNN, current_word, hidden_state = N, k_most_probable_words = N):\n",
        "    \n",
        "    prob = torch.ones(vocab_size)\n",
        "    temp = [RNN.word2int[current_word]]\n",
        "    input = torch.tensor(temp).unsqueeze(1).long()\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        gpu = 1\n",
        "        input = input.cuda()\n",
        "\n",
        "    hidden_state = tuple([each.data for each in hidden_state])\n",
        "    gpu = 0\n",
        "    output, hidden_state = RNN(input, hidden_state)\n",
        "    ch = 1\n",
        "    prediction = torch.nn.functional.softmax(output, dim = ch).data\n",
        "\n",
        "    if train_on_gpu:\n",
        "        gpu = 1\n",
        "        prediction = prediction.cpu()\n",
        "\n",
        "    temp = [RNN.word2int[current_word]]\n",
        "    prediction = prediction.numpy()[0][torch.tensor(temp).item()]\n",
        "    gpu = 0\n",
        "    return prediction, hidden_state"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2d70a7f052bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_most_probable_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSw_PUG7vAs8"
      },
      "source": [
        "def sample(RNN, size, prime=\"The sun is getting low\", top_k=None):\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        gpu = 1\n",
        "        RNN.cuda()\n",
        "    else:\n",
        "        gpu = 0\n",
        "        RNN.cpu()\n",
        "\n",
        "    generated_text = prime.lower().split()\n",
        "    RNN.eval()\n",
        "    print(generated_text)\n",
        "    h = RNN.init_hidden(1)\n",
        "    s_len = len(generated_text) - 3\n",
        "    sent_prob = 1\n",
        "\n",
        "    for i in range(s_len):\n",
        "        sums = i + 3\n",
        "        prime_text = generated_text[i:sums]\n",
        "        predicted_probability, h = predict(RNN, generated_text[sums], h, k_most_probable_words = top_k)\n",
        "        sent_prob *= predicted_probability\n",
        "\n",
        "    return sent_prob"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "DjIOD13UvF5U",
        "outputId": "6778b141-fa54-4fef-ab05-3eaae929e565"
      },
      "source": [
        "model_name = 'rnn_1_layer_epoch_18000_data.net'\n",
        "\n",
        "with open(model_name, 'rb') as f:\n",
        "    isloaded = True\n",
        "    checkpoint = torch.load(f)\n",
        "\n",
        "VALUE = 1000\n",
        "val_1 = checkpoint['tokens']\n",
        "val_2 = checkpoint['n_hidden']\n",
        "val_3 = checkpoint['n_layers']\n",
        "loaded_RNN = LanguageRNN(val_1, n_hidden=val_2, n_layers=val_3)\n",
        "example_sentence = 'The cat ran over the table.'\n",
        "loaded_RNN.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "print(sample(loaded_RNN, VALUE, prime=example_sentence, top_k=50))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0d2e9c9780f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rnn_1_layer_epoch_18000_data.net'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0misloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rnn_1_layer_epoch_18000_data.net'"
          ]
        }
      ]
    }
  ]
}